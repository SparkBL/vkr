\section{Работа с имитационной моделью}
В данном разделе изложены подходы к работе с реализованным пакетом программ, показывающие течение процесса исследования при помощи имитационного моделирования и дополнительных утилит для расчета характеристик. В частности будет описан процесс моделирования с целью нахождения характеристик работы узла с двумя типами заявок. Также представлен метод параллельного запуска множества моделей с разной конфигурацией для создания большой выборки.
\subsection{Вычисление характеристик выходящих процессов модели RQ--системы с повторными вызовами и обратной связью}

В главе \ref{rq_3} описаны асимптотические результаты, в частности приближение характеристической функции числа обслуженных заявок разного типа за время $t$. Последующей задачей ставится определение области применимости полученного приближения. 

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{RQ.png}
	\caption{Модель RQ--системы с повторными вызовами и обратной связью} \label{rq_system}
\end{figure}

Поскольку решение было получено при асимптотическом условии бесконечной задержки заявок в источнике повторных вызовов, требуется определить, при каких параметрах модели асимптотические результаты становятся недостоверными. Для это цели как раз отлично подходит имитационное моделирование.

В первую очередь, импортируем модуль наш q\_analysis. Он, в свою очередь, содержит подмодуль simulation для имитационного моделирования. Именно содержит реализацию ранее описанной предметной области.
\begin{pyin}
	import q_analysis.simulation as q
\end{pyin}
Создадим модель и установим время моделирования, равное 1000000 условных единиц.
\begin{pyin} 
model = rq.Model()
model.set_time(0) 
model.set_end(100000)
model
\end{pyin}

\begin{pyout}
	Model{ time: 0, end : 1000000, event_queue_len : 0, num_components : 0, num_connections : 0 }
\end{pyout}

Далее добавим элементы модели (метод add\_producer). 

В модель добавятся следующие элементы: 
\begin{itemize}
	\item MMPP поток c матрицей $\Lambda$ следующего вида
		\begin{equation*}
			\Lambda =  \begin{bmatrix}
			1.0 & 0 &  0\\
			0 & 1.12 & 0\\
			0 & 0 &	0.45
			\end{bmatrix}
		\end{equation*} и матрицей $Q$
		\begin{equation*}
			\Lambda =  \begin{bmatrix}
				-0.4 & 0.3 &  0.1\\
				0.5 & -0.6 & 0.1\\
				0.3 & 0.6 &	-0.9
			\end{bmatrix}
		\end{equation*};
	\item Орбита с экспоненциальной задержкой с интенсивностью $1$;
	\item Простейший поток с экспоненциальной задержкой с интенсивностью $1$ (будет использоваться как источник вызываемых заявок прибора);
	\item Обслуживающий прибор с экспоненциальным временем обслуживания входящих и вызываемых заявок с интенсивностью $1.15$.
\end{itemize}
Чтобы обращаться к элементам модели, им даются ярлыки - input, call, orbit, node.


\begin{pyin}
model.add_producer(rq.MMPPInput(
[1,1.12,0.45],
[[ -0.4, 0.3, 0.1],
[0.5,-0.6,0.1],
[0.3,0.6,-0.9]],0,0),"input")
model.add_producer(rq.SimpleInput(rq.ExponentialDelay(1),1,0),"call")
model.add_producer(rq.Orbit(rq.ExponentialDelay(1)),"orbit")
model.add_producer(rq.RqtNode(rq.ExponentialDelay(1.15),rq.ExponentialDelay(1.15)),"node")
print("Components:",model.components())
\end{pyin}

\begin{pyout}
	Components: {'node': RQTNode, 'orbit': Orbit, 'input': MMPP, 'call': SimpleInput}
\end{pyout}

Далее требуется соединить элементы модели при помощи маршрутизаторов. Для этого используется метод add\_connection. В параметрах указывается ранее заданный ярлык элемента модели, потом его вход или выход, функция возвращает ярлык нового соединения.

\begin{pyin}
	model.add_connection("input","out_slot","node","in_slot")
\end{pyin}
В данном случае мы указали входящий поток input и его выход out\_slot как источник заявок, и прибор node и его вход in\_slot как вход для приходящих заявок. Получим следующий ключ, описывающий соединение:
\begin{pyout}
'input:out_slot:node:in_slot'
\end{pyout}
С помощью полученной строки в последствии можно обращаться к соответствующими маршрутизатору при помощи метода reader\_at.

Далее добавляются остальные соединения. Для обслуживающего прибора маршрутизатор для обслуженных заявок не будет их сохранять в памяти. Это достигается использованием метода add\_hanging\_output\_noqueue
\begin{pyin}
model.add_connection("call","out_slot","node","call_slot")
model.add_connection("node","orbit_append_slot","orbit","in_slot")
orb = model.add_connection("orbit","out_slot","node","orbit_slot")
output = model.add_hanging_output_noqueue("node","out_slot")
print("Connections",model.routers())
\end{pyin}

\begin{pyout}
Connections {
'onq:node:out_slot': Router{ queue_len: 0 },
'orbit:out_slot:node:orbit_slot': Router{ queue_len: 0 },
'node:orbit_append_slot:orbit:in_slot': Router{ queue_len: 0 },
'input:out_slot:node:in_slot': Router{ queue_len: 0 },
'call:out_slot:node:call_slot': Router{ queue_len: 0 }
}
\end{pyout}

Ярлыки маршрузиторов называются по следующей схеме:
\begin{itemize}
	\item \textit{ ярлык выходного элемента :  имя выхода :  ярылк входного элемента : имя входа };
	\item для аккумулирующего входного маршрузитора (model.add\_hanging\_input) --- \textit{i :  ярылк входного элемента : имя входа}
	\item для аккумулирующего выходного маршрузитора (model.add\_hanging\_output) --- \textit{o :  ярылк выходного элемента : имя выхода}
	\item для выходного маршрузитора (model.add\_hanging\_output\_noqeuue) --- \textit{onq :  ярылк выходного элемента : имя выхода}
\end{itemize}

Добавим сбор статистики с интервалом в 20 условных единиц, что будет означать, что мы измеряем, сколько заявок было обслужено в системе за $t = 20$:

\begin{pyin}
model.router_at(output).add_reader(rq.IntervalRouterReader(20),"stat")
model.router_at(output).readers()
\end{pyin}
\begin{pyout}
'stat': IntervalRouterReader
\end{pyout}

Теперь когда модель создана, нам требуется описать, как именно будет проходить ее запуск. Маршрутизация определяет топологию передачи заявок по системе, однако порядок взаимодействия элементов модели указывается в качестве отдельного алгоритма, так как, в зависимости от специфики задачи, он может варьироваться.
Процесс моделирования сводится к итеративному вызову метода produce у элементов модели с указанием в качестве параметра текущего времени моделирования. Результат работы produce (список моментов наступления предстоящих событий) передается в функцию модели aggregate для того, чтобы далее смещать время на нужные моменты. Именно порядок вызовов produce составляет алгоритм моделирования. В данно случае он будет следующим:
\begin{enumerate}
	\item генерация очередной заявки входящих потоком;
	\item возвращение заявок с орбиты;
	\item генерация очередной заявки источником вызываемых заявок;
	\item обслуживание заявки;
	\item сбор заявок, не сумевших захватить прибор.
\end{enumerate}

Построим цикл:
\begin{pyin}
from tqdm import tqdm
e = model.end()
with tqdm(total=int(e)) as pbar:     
t = c = 0
while True:
    c+=1 
    told = t
    t = model.next_step()
    pbar.update(t-told)
    model.aggregate(model.component_at("input").produce(t))
    model.aggregate(model.component_at("orbit").produce(t))
    model.aggregate(model.component_at("call").produce(t))
    model.aggregate(model.component_at("node").produce(t))
    model.aggregate(model.component_at("orbit").append(t))
    if model.is_done():
        break
print("Time: ",model.time())
print("Iters: ",c)
\end{pyin}

\begin{pyout}
Time:  1000000.0437646629
Iters:  21710021
\end{pyout}

По окончании моделировании мы можем проверить, какое распределение числа обслуженных заявок за интервал $20$. Для этого обратимся к сборщику статистики маршрутизатора с ярлыком output и вызовем метод get\_distribution\_2d. Этот метод построит распределением вероятности числа обслуженных заявок двух типов --- входящих и вызванных.
\begin{pyin}
distr = model.router_at(output).reader_at('stat').get_distribution_2d()
import plotly.graph_objects as go
fig = go.Figure(data=[go.Surface(z=distr) ])

fig.update_traces(contours_z=dict(show=True, usecolormap=False,
highlightcolor="limegreen", project_z=True))

fig.update_layout(title='Model 2d distribution', autosize=False,
width=1000, height=1000,
margin=dict(l=65, r=50, b=65, t=90))

fig.show()
\end{pyin}

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4,width=\textwidth]{model_2d_distr.png}
	\caption{Распределение числа обслуженных заявок по окончании имитационного моделирования} 
	\label{model_2d_distr}
\end{figure}

Далее получим характеристики выходящих процессов:

\begin{pyin} [rqtestchar]
print("Mean  called: {0},\nMean input: {1},\nVariation called: {2},\nVariation input: {3}".format(
model.router_at(output).reader_at('stat').get_mean_called(),
model.router_at(output).reader_at('stat').get_mean_input(),
model.router_at(output).reader_at('stat').get_variation_called(),
model.router_at(output).reader_at('stat').get_variation_input()))
\end{pyin}

\begin{pyout} 
Mean  called: 1.476929538590772,
Mean input: 19.793515870317407,
Variation called: 0.9226633215974042,
Variation input: 0.9463029320729057
\end{pyout}

В ячейке \ref{rqtestchar} представлены значения среднего числа обслуженных вызванных и входящих заявок, вариации числа обслуженных вызванных и входящих заявок соответственно.

Также мы можем экспортировать результаты в файл для работы в друго среде при помощи NumPy:
\begin{pyin} [rqtestchar]
np.array(distr).tofile('example_distr.txt')
\end{pyin}
Таким образом мы смогли получить характеристики выходящих процессов рассматриваемой модели системы и визуализировать полученный результат, используя ту же среду выполнения.

\subsection{Исследование зависимости распределения заявок на орбите и времени ожидания}
В данном разделе рассматривается применение имитационной модели для решения задачи, требующей большой выборки данных. Суть задачи составляет подтверждение наличия зависимости между числом заявок на орбите и временем ожидания заявки до ее обслуживания на приборе в системе, изображенной на рисунке \ref{rq_system}. Данная задача важна для понимания функционирования источника повторных вызовов в связке с обслуживающим прибором?????. Поскольку требуется рассмотреть модель с различными параметрами орбиты и входящего потока, будет проводится ряд запусков имитационной модели с различной конфигурацией для образования выборки, на основе которой в последствии будет производится поиск корреляции.

На число заявок на орбите, как и на время их обслуживания непосредственно влияют следующие параметры модели:
\begin{enumerate}
	\item интенсивность входящего потока;
	\item частота возращения заявок с орбиты;
	\item интенсивность обслуживания прибора.
\end{enumerate} 

Перечисленные параметры будут варьироваться от модели.
Для хранения данных о моделировании и собираемых характеристиках работы моделей будем использовать словарь:
\begin{pyin} 
models = []
models_desc = []
\end{pyin}

Поскольку запусков будет много, будет запускать их в разных потоках для максимальной эффективности. Для этого объявим функции для генерации модели и запуска алгоритма. Это позволит нам использовать одну и ту же логику при параллельном запуске. Для упрощения задачи моделирования будет использоваться простейший входящий поток заявок, также зафиксируем интенсивность вызова заявок на значении 1. Для подсчета времени ожидания нам достаточно обновлять для каждой прошедшей заявки момент времени, в который он уходила с орбиты. В свою очередь для подсчета количества заявок на орбите нам потребуется учитывать, сколько заявок пришло на орбиту, и сколько ушло. Для этой цели прикрепим к маршрутизаторам, по котором заявки проходят через орбиту, счетчики TimeCounter.

\begin{pyin} 
def sim_task(i):
   t = c = 0
   while True:
      c+=1 
      t = models[i].next_step()
      models[i].aggregate(models[i].component_at("input").produce(t))
      models[i].aggregate(models[i].component_at("orbit").produce(t))
      models[i].aggregate(models[i].component_at("call").produce(t))
      models[i].aggregate(models[i].component_at("node").produce(t))
      models[i].aggregate(models[i].component_at("orbit").append(t))
      if models[i].is_done():
         print('#',end='')
         models[i].flush()
         break
\end{pyin}         

\begin{pyin}
def create_model(inp_i,orb_i,node_i):
model = rq.Model()
model.set_time(0) 
model.set_end(100000)

model.add_producer(rq.SimpleInput(rq.ExponentialDelay(inp_i),1,0),"input")
model.add_producer(rq.SimpleInput(rq.ExponentialDelay(1),1,0),"call")
model.add_producer(rq.Orbit(rq.ExponentialDelay(orb_i)),"orbit")
model.add_producer(rq.RqtNode(rq.ExponentialDelay(node_i),rq.ExponentialDelay(1.15)),"node")

model.add_connection("input","out_slot","node","in_slot")
model.add_connection("call","out_slot","node","call_slot")
orb_i = model.add_connection("node","orbit_append_slot","orbit","in_slot")
orb_o = model.add_connection("orbit","out_slot","node","orbit_slot")
output = model.add_hanging_output_noqueue("node","out_slot")

model.router_at(orb_i).add_reader(rq.AttemptCounter(),"attempt_count")
model.router_at(orb_i).add_reader(rq.TimeCounter(),"count")
model.router_at(orb_o).add_reader(rq.TimeCounter(),"count")
return model
\end{pyin}


Далее сгенерируем модели. Интенсивность входящего потока будет находится в границах $[0.8,1.5]$ c шагом $0.1$, орбита аналогично, а интенсивность обслуживания будет варьироваться в диапазоне $[1.6,2.3]$ с шагом 0.1, поскольку одним их условий стационарного режима для данной системы является интенсивность обслуживания, превосходящая общую интенсивность входящего потока. Время моделирования установим в 100000 условных единиц, чего хватит для получения достоверных значений исследуемых характеристик. Для генерации моделей применим тройной вложенный цикл, итерации которого используют ранее установленный диапазоны:
\begin{pyin} 
input_intensity_range = np.arange(0.8, 1.5001, 0.1)
orbit_intensity_range = np.arange(0.8, 1.5001, 0.1)
node_intensity_range = np.arange(1.6, 2.3001, 0.1)
m_index = 0

for inp in list(input_intensity_range):
for orb in list(orbit_intensity_range):
for nod in list(node_intensity_range):
   m = {}
   m['model_index'] = m_index
   m_index+=1
   m['input_intensity'] = inp
   m['orbit_intensity'] = orb
   m['node_intensity'] = nod
   models_desc.append(m)
   models.append(create_model(inp,orb,nod))
\end{pyin}

Для каждого запуска будем хранить заданные параметры в словаре, который в последствии также наполнится другими данными о моделировании, что позволит нам создать полноценную выборку для анализа:

\begin{pyin}
for m in models_desc:
   print(m)
\end{pyin}

\begin{pyprint}
{'model_index': 0, 'input_intensity': 0.8, 'orbit_intensity': 0.8, 'node_intensity': 1.55}
{'model_index': 1, 'input_intensity': 0.8, 'orbit_intensity': 0.8, 'node_intensity': 1.65}
{'model_index': 2, 'input_intensity': 0.8, 'orbit_intensity': 0.8, 'node_intensity': 1.75}
{'model_index': 3, 'input_intensity': 0.8, 'orbit_intensity': 0.8, 'node_intensity': 1.85}
...
\end{pyprint}

Итак, получилось 448 моделей с различными характеристиками. Запустим их, каждую в отдельном процессе, при помощи объекта ThreadPool из встроенной библиотеке Python multiprocessing \cite{multiproc}, предназначенной для конкурентной работы:
\begin{pyin}
print('#'*(len(models)-1))
from multiprocessing.pool import ThreadPool
r = list(range(0,len(models)-1))
with  ThreadPool(processes=12) as p:
   p.map(sim_task, r )
\end{pyin}

Для последующего анализа рассчитаем ряд показателей:
\begin{itemize}
	\item среднее число заявок на орбите;
	\item среднее время ожидания заявки до обслуживания;
	\item максимальное число заявок на орбите;
	\item максимальное время ожидания заявки;
	\item 95-ый и 99-ый процентили числа заявок на орбите;
	\item 95-ый и 99-ый времени ожидания заявки.
\end{itemize}

Пример полученный таблицы с характеристиками:

\begin{table}[H] 
	\centering
	\caption{Показатели для оценки зависимости числа заявок на орбите и времени ожидания заявки}
	\label{sim_result_1}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|} 
\hline
index & $\lambda$ &  $\sigma$ &  $\mu_1$ &   os\_mean &   wt\_mean &      os\_max &     wt\_max &       os\_q99 &     wt\_q99 \\
\hline
0  &             0.80 &             0.80 &            1.60 &    20.00 &     4.88 & 3153.85 &   85.54 &  339.71 &   28.93 \\
\hline
1  &             0.80 &             0.80 &            1.70 &    20.00 &     4.29 & 3513.15 &   59.67 &  205.72 &   25.65 \\
\hline
2  &             0.80 &             0.80 &            1.80 &    20.00 &     4.06 & 3686.25 &   55.43 &  198.64 &   24.73 \\
\hline
3  &             0.80 &             0.80 &            1.90 &    20.00 &     3.78 & 3842.80 &   60.25 &  145.26 &   22.40 \\
\hline
4  &             0.80 &             0.80 &            2.00 &    20.00 &     3.53 & 4165.60 &   50.33 &  121.25 &   22.75 \\
\hline
5  &             0.80 &             0.80 &            2.10 &    20.00 &     3.34 & 4319.15 &   41.40 &   83.00 &   20.01 \\
\hline
6  &             0.80 &             0.80 &            2.20 &    20.00 &     3.20 & 4401.04 &   49.76 &   62.71 &   19.11 \\
\hline
7  &             0.80 &             0.90 &            1.60 &    20.00 &     4.20 & 3514.95 &   57.31 &  186.38 &   24.10 \\
\hline
8  &             0.80 &             0.90 &            1.70 &    20.00 &     4.02 & 3696.41 &   54.64 &  187.74 &   24.29 \\
\hline
9  &             0.80 &             0.90 &            1.80 &    20.00 &     3.68 & 3795.79 &   47.19 &  134.48 &   22.14 \\
\hline
10 &             0.80 &             0.90 &            1.90 &    20.00 &     3.47 & 4081.71 &   46.49 &   97.16 &   20.18 \\
\hline
11 &             0.80 &             0.90 &            2.00 &    20.00 &     3.24 & 4347.64 &   43.40 &   69.71 &   19.49 \\
\hline
12 &             0.80 &             0.90 &            2.10 &    20.00 &     3.14 & 4557.42 &   49.86 &   69.03 &   19.27 \\
\hline
13 &             0.80 &             0.90 &            2.20 &    20.00 &     3.01 & 4693.59 &   41.51 &   62.88 &   18.56 \\
\hline
14 &             0.80 &             1.00 &            1.60 &    20.00 &     3.98 & 3796.29 &   62.06 &  207.70 &   24.13 \\
\hline
\end{tabular}
\end{table}

После того, как выборка создана, рассмотрим распределение каждой из характеристик. На рисунке \ref{orbit_size_plot} представлены распределения вероятностей числа заявок на орбите во время моделирования. Как видно из \ref{sim_result_1} среднее значение для большей части распределений наблюдается в значении 20:

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4,width=\textwidth]{orbit_size_plot.png}
	\caption{Распределения числа заявок на орбите} 
	\label{orbit_size_plot}
\end{figure}

На рисунке \ref{wait_time_plot} представлены распределения времени до обслуживания заявки. В среднем, заявка достигала прибора за 4 условных единицы:

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4,width=\textwidth]{wait_time_plot.png}
	\caption{Распределения числа заявок на орбите} 
	\label{wait_time_plot}
\end{figure}

Для того, чтобы выявить зависимости между показателями воспользуемся графиками рассеяния, где каждому наблюдению будет соответствовать точка на декартовой плоскости. По каждой из осей отложены рассматриваемые показатели, и в случае, если между ними имеется корреляционная зависимость, на диаграмме это будет представлено в виде определенной закономерности, согласно которой расположены точки. В случае положительной корреляции оба значения будут расти и наоборот:
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4,width=\textwidth]{os_wt_scatter_plot.png}
	\caption{Распределения числа заявок на орбите} 
	\label{os_wt_scatter_plot}
\end{figure}

!ВЫВОДЫ ИЗ ГРАФИКА

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4,width=\textwidth]{os_wt_corr_map.png}
	\caption{Распределения числа заявок на орбите} 
	\label{os_wt_corr_map}
\end{figure}

!ВЫВОДЫ ИЗ ГРАФИКА

!Выводы

\subsection{Апробация машинного обучения}
В данной главе описывается апробирование подхода к анализу систем массового обслуживания при помощи машинного обучения, а именно --- предсказывание коэффициента вариации длин интервалов между моментами покидания заявок системы. Данный метод широко используется во многих других областях науки и является универсальным: подходит для задач регрессии, временных рядов, а также классификации и кластеризации \cite{libbrecht2015machine,shinde2018review,soofi2017classification}. В теории массового обслуживания также есть примеры исследования, в которых успешно используется машинное обучение \cite{ojeda2021learning,xue2016scheduling,balla2018reliability}.

\subsubsection{Разведочный анализ}
В данном случае машинное обучение будет использоваться для решения задачи регрессии. Для этой цели, при помощи ранее описанных инструментов, было проведено около 286 тысяч запусков имитационной модели при различных параметрах входящего потока, орбиты и обслуживающего прибора для создания выборки, на основе которой и будет решена задача.

Исходная выборка имеет 9 признаков:
\begin{enumerate}
	\item elapsed --- время работы имитационной модели в секундах. Данный признак был добавлен в утилитарных целях, в частности, для последующей оптимизации работы модели при нестандартных параметрах. Действительное число.
	\item mean\_input --- среднее число обслуженных заявок входящего потока за интервал моделирования. Действительное число.
	\item var --- коэффициент вариации длин интервалов между моментами наступления событий во входящем потоке. Действительное число.
	\item alpha --- интенсивность вызова заявок прибором ($\alpha$). Действительное число.
	\item lg --- интенсивность входящего потока \eqref{eq_lg}. Действительное число.
	\item mu1 --- интенсивность обслуживания входящих заявок ($\mu_1$). Действительное число.
	\item mu2 --- интенсивность обслуживания вызванных заявок ($\mu_2$). Действительное число.
	\item sigma --- интенсивность обращений заявок с орбиты ($\sigma$). Действительное число.
	\item var\_input --- коэффициент вариации выходящего процесса. Действительное число. Является целевой переменной для предсказаний.
\end{enumerate}

Все признаки имеют 270420 (часть экспериментов выбыли из-за превышения временного лимита на выполнение) ненулевых значений и распределены следующим образом	
\begin{table}[H]
	\centering
	\caption{Распределение признаков}
	\label{table_feature_distr}
	\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|}
		\hline
		& elapsed & mean\_input & var\_input &     alpha &        lg &       mu1 &       mu2 &     sigma &       var \\
		\hline
		mean & 7.36 &       5.52 & 1.11 &      1.26 &      1.90 &      2.97 &      2.71 &      1.41 &      1.32 \\
		\hline
		std & 23.16 &       5.43 & 0.20 &      0.91 &      0.68 &      0.66 &      0.81 &      0.86 &      0.31 \\
		\hline
		min & 0.01 &       0.00 & 0.71 &      0.00 &      1.00 &      1.20 &      1.00 &      0.01 &      1.00 \\
		\hline
		10\% & 0.79 &       0.57 & 0.93 &      0.20 &      1.00 &      2.00 &      1.40 &      0.21 &      1.05 \\
		\hline
		20\% & 1.29 &       1.15 & 1.00 &      0.40 &      1.20 &      2.40 &      2.00 &      0.61 &      1.09 \\
		\hline
		30\% & 1.74 &       1.82 & 1.01 &      0.60 &      1.40 &      2.60 &      2.20 &      0.81 &      1.14 \\
		\hline
		40\% & 2.19 &       2.66 & 1.03 &      0.80 &      1.60 &      2.80 &      2.60 &      1.21 &      1.18 \\
		\hline
		50\% & 2.70 &       3.70 & 1.06 &      1.20 &      1.80 &      3.00 &      2.80 &      1.41 &      1.24 \\
		\hline
		60\% & 3.34 &       5.03 & 1.09 &      1.40 &      2.00 &      3.20 &      3.00 &      1.81 &      1.30 \\
		\hline
		70\% & 4.32 &       6.77 & 1.14 &      1.80 &      2.20 &      3.40 &      3.20 &      2.01 &      1.37 \\
		\hline
		80\% & 6.21 &       9.23 & 1.20 &      2.00 &      2.60 &      3.60 &      3.60 &      2.41 &      1.48 \\
		\hline
		90\% & 11.76 &      13.25 & 1.32 &      2.60 &      2.80 &      3.80 &      3.80 &      2.61 &      1.67 \\
		\hline
		95\% & 22.72 &      16.87 & 1.46 &      3.00 &      3.20 &      3.80 &      3.80 &      2.81 &      1.87 \\
		\hline
		99\% & 104.70 &      24.02 & 1.86 &      3.40 &      3.40 &      3.80 &      3.80 &      2.81 &      2.45 \\
		\hline
		max & 419.53 &      35.89 & 5.99 &      3.60 &      3.60 &      3.80 &      3.80 &      2.81 &      8.19 \\
		\hline
	\end{tabular}
\end{table}
На основе сводки из таблицы \ref{table_feature_distr} можно заметить, что в среднем время моделирования занимало 7.36 секунд, половина экспериментов была запущена с интенсивностью входящего потока 1.8, а максимальный коэффициент вариации выходящего процесса составил 8.19.



На данном этапе мы можем избавиться от признаков, которые не будут участвовать в обучении модели: mean\_input и elapsed. Для оставшихся признаков построим графики рассеяния \cite{cox2007pairplot}. Данные диаграммы полезны для отображения многомерных данных, как в данном случае. С их помощью можно определить потенциальные взаимосвязи между количественными переменными.
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.8,width=\textwidth]{pairplot.png}
	\caption{Графики рассеяния признаков}
	\label{pairplot}
\end{figure}
\clearpage
На графике рассеяния \ref{pairplot} видно, что явную связь имеют коэффициент вариации входящего потока (var) и коэффициент вариации выходящего процесса (var\_input). Для более точного определения зависимостей построим для признаков тепловую карту коэффициента корреляции Пирсона
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.8,width=\textwidth]{pearson_heatmap.png}
	\caption{Тепловая карта корреляции признаков}
	\label{pearson_heatmap}
\end{figure}
На рисунке \ref{pearson_heatmap} можно наблюдать логичную корреляцию таких признаков, как интенсивность обслуживания входящих заявок (mu1) и интенсивность входящего потока (lg), а также интенсивность обслуживания вызванных заявок (mu2) и интенсивность их вызова (alpha). Для целевой переменной же можно наблюдать ранее выявленную корреляцию с коэффициентом вариации входящего потока и интенсивностью обращения заявок с орбиты (sigma), что так же ожидаемо, поскольку задержка заявок на орбите влияет на пропускную способность прибора.

\subsubsection{Построение предсказательных моделей}
Для настройки и обучения предсказательных моделей используется язык Python и библиотека для ансамблевого машинного обучения scikit-learn \cite{hackeling2017mastering}. Ансамблевые методы машинного обучения являются мощным и в то же время простым для понимая инструментом анализа данных. Он представляет собой метод обучения, где несколько моделей обучаются решению одной и той же задачи и объединяются для получения наиболее точных результатов. Ключевое преимущество такого метода заключается в том, что результат работы нескольких моделей будет иметь большую точность, чем результат только одной модели.
Будут обучены и протестированы следующие модели:
\begin{itemize}
	\item LinearRegression --- реализация метода наименьших квадратов. Будет использована для проверки правильности выборки и сравнения с другими, более сложными методами.
	\item RandomForest \cite{rigatti2017random} --- алгоритм, основывающийся на ансамбле решающих деревьев с разным ветвлением (зависит от порядка признаков), каждое из которых дает свой ответ на поставленную задачу, сам по себе являющийся неточным, однако при наличии большого количества деревьев, результат имеет хорошую точность.
	\item GradientBoost \cite{natekin2013gradient} --- обучение слабых моделей последовательно, таким образом, что каждая последующая исправляет ошибки предыдущих. Как правило, данный алгоритм превосходит в точности лес случайных деревьев.
	\item CatBoost \cite{hancock2020catboost} --- оригинальная реализация алгоритма градиентного бустинга компанией Яндекс. Самой компанией используется для улучшения поисковых результатов,  ранжирования рекомендаций пользователям и онлайн-аналитики. В общем случае является более точной, чем градиентный бустинг.
\end{itemize}

Первым шагом в обучении изложенных алгоритмов будет разбиение выборки на тестовую и обучающую, также выделение целевой переменной в отдельный вектор $y$. Обучающая выборка составила $70\%$ от общей. Далее листинги кода будут предложены в формате Python Notebook
\begin{pyin}
from sklearn.model_selection import train_test_split
x = df.drop(['var_input'], axis = 1)
y = df['var_input']

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3,random_state=9)

x_train = x_train.reset_index(drop = True)
y_train = y_train.reset_index(drop = True)
x_test = x_test.reset_index(drop = True)
y_test = y_test.reset_index(drop = True)
\end{pyin}

\begin{pyin}[xtrainsize]
x_train.shape, y_train.shape
\end{pyin}

\begin{pyprint}
((189168, 6), (189168,))
\end{pyprint}
\begin{pyin}[xtestsize]
x_test.shape, y_test.shape
\end{pyin}

\begin{pyprint}
	((81072, 6), (81072,))
\end{pyprint}
Так, размер обучающей выборки составил 189168 строк (ячейка \ref{xtrainsize}), размер тестовой выборки --- 81072 строк (ячейка \ref{xtestsize}).

Поскольку общая выборка не имеет пропущенных значений, этап заполнения пропусков был пропущен.

Поскольку большинство алгоритмов ожидают на вход нормализованных данных, то для корректного их обучения выполним Z--преобразование (ячейка \ref{standardscale}) при помощи объекта scikit-learn StandardScaler. Идея преобразования заключается в нормализации распределения каждого признака таким образом, что математическое ожидание будет равно нулю, а дисперсия --- единице. Нормализация производится для каждого признака индивидуально.
\begin{pyin}[standardscale]
from sklearn.preprocessing import StandardScaler
scal = StandardScaler()
scal.fit(x_train)
x_train_z = pd.DataFrame(scal.transform(x_train), columns = x_train.columns)
x_test_z = pd.DataFrame(scal.transform(x_test), columns = x_test.columns)
\end{pyin}
После преобразования необходимо выделить каждой из моделей значимые признаки. Это выполняется посредством предварительного обучения и анализа коэффициентов значимости \cite{hackeling2017mastering}

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{feat_lr.png}
	\caption{Значимость признаков для LinearRegression}
	\label{feat_lr}
\end{figure}
На рисунке \ref{feat_lr} видно, что для алгоритма LinearRegression значимыми признаками являются задержка заявок на орбите и коэффициент вариации входящего потока. В меньшей степени является значимой интенсивность обслуживания входящий заявок, и отрицательно сказывается на результате работы наличие признака lg.
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{feat_rf.png}
	\caption{Значимость признаков для RandomForest}
	\label{feat_rf}
\end{figure}
На рисунке \ref{feat_rf} можно наблюдать, что для алгоритма RandomForest наиболее значимыми оказались также вариация входящего потока и задержка заявок на орбите.
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.3]{feat_gb.png}
	\caption{Значимость признаков для GradientBoost}
	\label{feat_gb}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.3]{feat_cb.png}
	\caption{Значимость признаков для CatBoost}
	\label{feat_cb}
\end{figure}
Для алгоритмов GradientBoost и CatBoost значимыми признаками также выступают sigma и var. Основываясь на полученных данных, оставим в обучающей выборке для каждой модели только значимые признаки.

Задание гиперпараметров алгоритмов \cite{feurer2019hyperparameter} будем производить случайным подбором в 5 итераций при помощи алгоритма scikit-learn RandomizedSearchCV. Важно заметить, что из тестовой выборки не выделялась валидационная, так как RandomizedSearchCV содержит встроенную кросс-валидацию. Он позволяет, начиная с указанных начальных значений, итеративно подобрать оптимальные гиперпараметры для модели. Для метода наименьших квадратов эта процедура не производится, поскольку метод не допускает задания каких-либо параметров.
\begin{pyin}[rand_forest_param]
rf = RandomForestRegressor(n_jobs=-1)
parameters_rf = {'n_estimators': range (100,150, 10),
    'criterion':  ['squared_error'],
    'max_depth' : range(1,9,1),
    'min_samples_split': range(2,30,5),
    'min_samples_leaf':range(1,30,5)
}
search_rf = RandomizedSearchCV(rf, parameters_rf,n_jobs=-1, n_iter = 5)
search_rf.fit(x_train_rf, y_train)
search_rf.best_params_, search_rf.best_score_
\end{pyin}
\begin{pyprint}
({'n_estimators': 110,
    'min_samples_split': 2,
    'min_samples_leaf': 26,
    'max_depth': 7,
    'criterion': 'squared_error'},
0.7699992121816944)
\end{pyprint}
\begin{pyin}[random_forest_learn]
best_model_rf = search_rf.best_estimator_
best_model_rf.fit(x_train_rf, y_train)
y_pred_test_rf = best_model_rf.predict(x_test_rf)

print('MAE:', mean_absolute_error(y_test, y_pred_test_rf))
print('RMSE:', mean_squared_error(y_test, y_pred_test_rf, squared=False))
print('R2_score:', r2_score(y_test, y_pred_test_rf))
\end{pyin}
\begin{pyprint}
MAE: 0.06538199710376982
RMSE: 0.09781859274247506
R2_score: 0.7695224558769049
\end{pyprint}
В ячейке \ref{rand_forest_param} производится задание начальных значений гиперпараметров для алгоритма случайных деревьев. Среди параметров:
\begin{itemize}
	\item n\_estimators --- количество деревьев решений.
	\item criterion --- методы оценки ошибки в процессе обучения. По умолчанию выбрано среднеквадратическое отклонение.
	\item max\_depth --- максимальная глубина дерева.
	\item min\_samples\_split --- минимальное количество сэмплов, требуемое для расщепления вершины дерева.
	\item min\_samples\_leaf --- минимальное количество сэмплов, требуемое для превращения вершины в лист.
\end{itemize}
Далее производится подбор параметров алгоритма, дающих максимальную точность, измеряемую коэффициентом детерминации. Коэффициент детерминации является основной метрикой качества для решений задач регрессии \cite{gomar2011validation}. В данном случае, он составил 0.769.
В ячейке \ref{random_forest_learn} производится обучение модели с лучшими гиперпараметрами и оценка точности, которая проводится при помощи следующих метрик:  средняя абсолютная ошибка (MAE), среднеквадратическое отклонение (RMSE) и коэффициент детерминации (R2\_score).

Для остальных моделей использовалась та же последовательность операций. В итоге, были получены следующие результаты
\begin{figure}[H]
	\centering
	\includegraphics[scale=1,width=\textwidth]{model_accuracy.png}
	\caption{Оценка точности моделей}
	\label{model_accuracy}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=1,width=\textwidth]{pred_example.png}
	\caption{Сравнение предсказаний моделей}
	\label{pred_example}
\end{figure}
Как видно на рисунке \ref{model_accuracy}, CatBoost оказался самым точным среди выбранных алгоритмов --- результаты его предсказаний имеют наименьшую среднюю абсолютную и квадратические ошибки и наибольшее значение коэффициента детерминации, равное 0.774. Рассмотрение результатов предсказаний в целом показывает, что общая точность моделей находится в районе 80\%. Для апробирования подхода данный результат является в достаточной степени приемлемым. Также, можно предложить, почему точность моделей не оказалась выше: на рисунке \ref{pred_example} представлен отрезок тестового вектора значения коэффициента вариации выходящего процесса с наложением на него предсказаний. Можно заметить, что для значений, которые наиболее приближены к среднему по выборке, предсказания точны, однако для менее частых модели не смогли дать верный ответ. Это обусловлено слабой дисперсией в распределении значимых признаков в выборке (таблица \ref{table_feature_distr}), что приводит к переобучению моделей на определенном диапазоне значений признаков, делая предсказания для остальных случаев искаженными. Для улучшения качества предсказаний требуется изменить метод генерации параметров таким образом, чтобы признаки были распределены более равномерно и охватывали как можно больше возможных значений.
\clearpage